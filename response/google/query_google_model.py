import os

from dotenv import load_dotenv
from google import genai

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")


def query_google_model(model, question, prompt_context=None, instructions=None, image_data=None,
                       document_data=None):
    """
    Query a language model with the provided question and optional context, instructions,
    image data, and document data. This function is designed to interact with Google's
    language model API, sending prompts in a stream and yielding response chunks as they
    are processed. The function also gathers and yields token usage metadata corresponding
    to the input and output tokens from the model interaction.

    :param model: The specific language model to be queried.
    :type model: str
    :param question: The primary question or query string to submit to the model.
    :type question: str
    :param prompt_context: Additional context information to provide for the model,
        default is None.
    :type prompt_context: Optional[str]
    :param instructions: Specific directions or formatting instructions to guide
        the model's output, default is None.
    :type instructions: Optional[str]
    :param image_data: Additional image-related data to include in the prompt for
        visual-processing models, default is None.
    :type image_data: Optional[Any]
    :param document_data: Supplementary document-related data to include in the
        prompt, default is None.
    :type document_data: Optional[Any]
    :return: A generator that yields chunks containing content generated by the
        model and metadata summarizing token usage information.
    :rtype: Generator[Dict[str, Any], None, None]
    """
    client = genai.Client(api_key=api_key)

    content = []

    if prompt_context:
        content.append({f"Here is the context: {prompt_context}"})

    if instructions:
        content.append({f"instructions: {instructions}"})

    if image_data:
        content.append({f"Image Data: {image_data}"})

    if document_data:
        content.append({f"Document Data: {document_data}"})

    content.append({f"question: {question}"})

    token_metadata = {"prompt_tokens": None, "completion_tokens": None, "total_tokens": None}

    response = client.models.generate_content_stream(
        model=model,
        contents=content,
    )

    for chunk in response:
        if chunk:
            yield {"content": chunk.text}

        if hasattr(chunk, "usage_metadata"):
            token_metadata["prompt_tokens"] = chunk.usage_metadata.prompt_token_count
            token_metadata["completion_tokens"] = chunk.usage_metadata.candidates_token_count
            token_metadata["total_tokens"] = chunk.usage_metadata.total_token_count

    yield {"metadata": token_metadata}
