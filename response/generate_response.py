from prompt_generation.prompt_generation import generate_prompt
from prompt_generation.query_local_model import query_local_model
from response.anthropic.query_anthropic_model import query_anthropic_model
from response.deepseek.query_deepseek_model import query_deepseek_model
from response.google.query_google_model import query_google_model
from response.openai.query_openai_model import query_openai_model
from utilities.count_tokens import count_tokens
from models.api_list import APIList
from models.user import User
from models import get_db
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def generate_response(
    provider: str,
    model: str,
    question: str,
    prompt_context: list = None,
    instructions: str = None,
    image_data: list = None,
    document_data: list = None,
    api_key: str = None,
    user_id: int = None
) -> str:
    """
    Generates a response based on the input parameters by selecting the appropriate provider
    and invoking the corresponding model's query function.

    Args:
        provider (str): The name of the provider to use for querying a model.
        model (str): The specific model within the selected provider to query.
        question (str): The question or query string to send to the model.
        prompt_context (list, optional): List of contextual strings for response generation.
        instructions (str, optional): Additional guiding instructions for response generation.
        image_data (list, optional): List of image data for compatible models.
        document_data (list, optional): List of document data for compatible models.
        api_key (str, optional): API key for tracking token usage.
        user_id (int, optional): User ID for tracking token usage.

    Returns:
        str: The response generated by the queried model.
    """
    try:
        # Generate response based on provider
        if provider == "deepseek":
            response = query_deepseek_model(model, question, prompt_context, instructions, image_data, document_data)
        elif provider == "openai":
            response, total_tokens_used = query_openai_model(model, question, prompt_context, instructions, image_data, document_data)
        elif provider == "anthropic":
            response = query_anthropic_model(model, question, prompt_context, instructions, image_data, document_data)
        elif provider == "google":
            response = query_google_model(model, question, prompt_context, instructions, image_data, document_data)
        else:
            response = query_local_model(generate_prompt(question, prompt_context, instructions, image_data, document_data))

        # Count tokens for question and response
        question_tokens = count_tokens(question, model)
        response_tokens = count_tokens(response, model)

        # Count tokens for prompt context if present
        context_tokens = 0
        if prompt_context:
            for context in prompt_context:
                context_tokens += count_tokens(context, model)

        # Calculate total tokens used
        if provider == "openai":
            # Use the token count directly from OpenAI's response
            total_tokens_used = total_tokens_used
        else:
            total_tokens_used = question_tokens + response_tokens + context_tokens

        # Update token usage in database
        db = next(get_db())
        try:
            if api_key:
                api_entry = APIList.get_by_api_key(db, api_key)
                if api_entry:
                    api_entry.tokens_used += total_tokens_used
                    api_entry.tokens_remaining = api_entry.total_tokens - api_entry.tokens_used
                    db.commit()
                    logger.info(f"Updated token usage for API key {api_key}: {total_tokens_used} tokens used")
            elif user_id:
                user = User.get_by_id(db, user_id)
                if user:
                    user.tokens_used += total_tokens_used
                    user.tokens_remaining = user.total_tokens - user.tokens_used
                    db.commit()
                    logger.info(f"Updated token usage for user {user_id}: {total_tokens_used} tokens used")
        except Exception as e:
            logger.error(f"Error updating token usage in database: {str(e)}")
        finally:
            db.close()

        return response

    except Exception as e:
        logger.error(f"Error in generate_response: {str(e)}")
        raise